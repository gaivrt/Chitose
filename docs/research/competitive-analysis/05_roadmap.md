# 改进路线图

> 战略定位：不堆功能，在少数维度做到最好（延迟、lip sync、记忆），保持架构简洁。

## P0 — 立即

### 中文 STT 替换
- **问题**：Deepgram nova-3 中文识别效果差
- **方案**：FunASR（阿里开源，需自部署）或 Whisper
- **目标**：中文识别准确率达到可用水平
- **与 TODO.md 对齐**：已列为高优先级

### 记忆系统
- **问题**：三个竞品都没有好的记忆系统，这是差异化机会
- **方案**：参考 OpenClaw 研究成果，实现 hybrid search 记忆
- **目标**：跨会话记住用户偏好和历史话题
- **参考**：`docs/research/openclaw/` 系列文档

## P1 — 近期

### Bilibili 弹幕集成
- **问题**：直播场景是 AI VTuber 核心需求，竞品中 Luna AI 支持 12 平台
- **方案**：先做 B站一个平台，做好做透
- **目标**：读取弹幕作为文字输入，支持过滤和优先级
- **与 TODO.md 对齐**：已列为中优先级

### TTS/STT Adapter 抽象层
- **问题**：当前硬编码 ElevenLabs + Deepgram，无法切换
- **方案**：借鉴 Open-LLM-VTuber 的 adapter 设计，定义接口
- **目标**：新增 provider 只需实现接口，不改核心代码

### 表情 + 动作系统
- **问题**：芊芊模型自带 31 个表情预设、身体旋转参数、12+ 道具切换，
  但当前仅接入了嘴巴开合一个参数，大量能力闲置
- **方案**：
  - 表情驱动：LLM 输出情感标签 → 触发对应 exp3 预设
    （如：开心→星星眼、害羞→脸红、困惑→问号、生气→生气）
  - Idle 动作：身体左右摆动（ParamBodyAngleZ）、呼吸（ParamBreath）、
    头部微动（ParamAngle XYZ），用正弦波或 Perlin noise 驱动
  - 说话动作：语音节奏驱动头部轻微点头和身体摆动
  - 道具切换：特定场景触发（如聊游戏→打游戏、唱歌→话筒）
- **目标**：角色从"会动嘴的立绘"变成"有生命感的虚拟形象"

## P2 — 中期

### Lip Sync 升级：Phoneme → Viseme
- **问题**：FFT 频率分析无法区分元音口型
- **方案**：引入轻量 phoneme 识别模型，映射到 viseme
- **目标**：不同元音对应不同口型，显著提升自然度

### 测试覆盖
- **问题**：三个项目都零测试，这是行业通病
- **方案**：核心模块（config、记忆、adapter）单元测试
- **目标**：关键路径有测试保障，CI 自动运行

### Plugin 系统
- **问题**：竞品都没有 plugin 系统，扩展性受限
- **方案**：基于 Python entry_points 或简单的钩子机制
- **目标**：第三方可以开发插件而不 fork 主仓库

## P3 — 远期

### 3D / VRM 支持
- 当前 Live2D 覆盖 2D VTuber 场景
- VRM 格式可覆盖 3D VTuber 场景
- 优先级低，视社区需求决定

### 多直播平台
- P1 先做好 B站，验证架构
- 后续按需扩展 YouTube、Twitch 等
- 平台适配层应在 P1 的 B站集成中就设计好

### WebUI 配置面板
- 当前通过 YAML + 环境变量配置
- 远期提供 Web 界面方便非技术用户
- 优先级最低，当前配置方式对开发者足够

## 优先级决策逻辑

| 优先级 | 核心考量 |
|--------|---------|
| P0 | 修复明显短板（中文 STT），抓住竞品空白（记忆） |
| P1 | 补齐核心场景（直播），提升可扩展性（adapter） |
| P2 | 技术深度（lip sync），工程质量（测试） |
| P3 | 覆盖面扩展，视社区反馈决定 |
