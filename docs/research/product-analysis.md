# Chitose 产品分析：用户需求、市场定位与技术路线

> 基于竞品分析（Luna AI / Open-LLM-VTuber）、市场调研、技术架构评估的综合分析。

## 一、目标用户画像

### 主要用户：AI VTuber 创作者/运营者
- 想做 AI 直播但缺乏技术能力的个人创作者
- 小型 VTuber 团队，想用 AI 辅助或替代真人值班
- 技术爱好者，想搭建自己的 AI 虚拟形象

### 次要用户：观众
- 18-34 岁为主，B站核心用户群
- 期望实时互动、有人格深度、情感表达丰富的虚拟形象

## 二、用户痛点分析

### 创作者痛点
1. **技术门槛高** — 现有开源方案要么代码质量差（Luna AI God Object 4257行），要么配置复杂
2. **延迟不可接受** — 传统 pipeline 端到端 1.3s+，观众体验差
3. **角色没有"生命感"** — 大多数方案只有嘴巴开合，没有表情、idle 动作、情感表达
4. **人设容易崩** — 长时间直播 LLM 会遗忘设定，前后矛盾
5. **无法记住观众** — 没有跨会话记忆，每次直播都是"初次见面"
6. **Provider 锁定** — 硬编码单一 TTS/STT/LLM，无法根据需求切换

### 观众痛点
1. **互动质量低** — AI 回复机械、不记得之前说过什么
2. **表情僵硬** — 只有嘴巴动，像"会说话的立绘"
3. **响应慢** — 发弹幕后等很久才有反应

## 三、Chitose 要解决的核心问题

> 核心命题：让 AI VTuber 从"技术 demo"变成"有生命感的虚拟角色"

### 差异化定位（不堆功能，少数维度做到最好）

| 维度 | 竞品现状 | Chitose 目标 |
|------|---------|-------------|
| 延迟 | 1.3s+（batch 模式） | <500ms（LiveKit 流式） |
| Lip sync | 二值开关 / RMS 音量 | FFT 频率分析 → Phoneme→Viseme |
| 记忆 | 无或已移除 | hybrid search 跨会话记忆 |
| 表情动作 | 无 | LLM 情感标签 → 31 表情预设 + idle 动作 |
| 架构 | God Object / 过度抽象 | 模块化、精简、LiveKit 原生 |

## 四、关键洞察：直播场景下 STT 不是刚需

### 场景 A：直播互动（核心场景）
- 输入来源：**弹幕文字**，不是语音
- STT 完全不需要，VAD 也不需要
- Pipeline 简化为：弹幕文字 → LLM → TTS → 语音 + Lip sync
- 延迟大幅降低（砍掉 STT ~400ms + VAD 延迟）

### 场景 B：私聊/陪伴（次要场景）
- 输入来源：用户语音或文字
- STT 在语音输入时需要
- 当前架构已支持（Deepgram STT + 文字输入双通道）

### 结论
- 中文 STT 替换优先级应降低——直播场景根本不用 STT
- 应优先做弹幕集成（文字输入），这才是直播的核心输入通道
- STT 推迟到"语音陪伴"场景时再优化

## 五、技术支撑

### 已有优势
- **LiveKit 流式架构** — 端到端低延迟的基础，竞品没有
- **FFT lip sync** — 比竞品的二值/RMS 方案更自然
- **模块化代码** — 比 Luna AI 的 God Object 好维护得多

### 需要建设的能力

1. **弹幕输入通道** — bilibili-api-python / WebSocket + Protobuf，含过滤/优先级排序
2. **记忆系统** — hybrid search（向量 0.7 + BM25 0.3），SQLite + sqlite-vec + FTS5
3. **表情 + 动作系统** — LLM 情感标签 → 表情预设，Perlin noise 驱动 idle 动作
4. **Adapter 抽象层** — TTS/LLM 接口定义，新 provider 只需实现接口

## 六、新增 Feature 建议

### 高价值（直播场景直接受益）

| Feature | 问题 | 方案 | 价值 |
|---------|------|------|------|
| 弹幕智能选择 | 弹幕量大，不能每条都回 | 规则过滤 + LLM 判断"最值得回" | 竞品都没做好 |
| 观众欢迎/识别 | 新观众进入无反应 | 监听进入事件 + 记忆系统个性化打招呼 | 留存关键 |
| SC/礼物反应 | 送礼无特殊反应 | 监听礼物事件 → 感谢语 + 特殊表情 | 影响变现 |
| 场景感知 + 话题引导 | AI 只能被动回复 | 冷场检测 → 主动发起话题 | 解决冷场 |

### 中等价值

- **多语言自动切换** — 检测弹幕语言 → 自动切换回复和 TTS 语言
- **语音风格/情感 TTS** — LLM 情感标签同时驱动表情和 TTS 风格
- **OBS 集成优化** — Browser Source 直接可用，透明背景，字幕叠加

### 探索性（长期）

- **AI 玩游戏** — 屏幕共享 + AI 评论画面（AIRI 已验证可行）
- **AI 唱歌** — 歌声合成模型 SVC（B站需求高）
- **多 AI 联动** — 两个 Agent 互相对话/辩论

## 七、修订后的优先级

### P0 — 核心直播能力
1. B站弹幕集成 ← 从 P1 提升
2. 表情 + 动作系统 ← 从 P1 提升
3. 记忆系统 — 保持

### P1 — 直播体验完善
4. 弹幕智能选择 + 优先级队列 ← 新增
5. 观众欢迎/识别 ← 新增
6. SC/礼物反应 ← 新增
7. 场景感知 + 主动话题 ← 新增

### P2 — 技术深度
8. Adapter 抽象层 — 从 P1 降级
9. Lip Sync Phoneme→Viseme — 保持
10. 语音风格/情感 TTS ← 新增
11. 测试覆盖 — 保持

### P3 — 扩展
12. 中文 STT 替换 ← 从 P0 降级
13. Plugin 系统、多直播平台、OBS 集成优化
14. 3D/VRM、WebUI、配置热更新、日志、监控

### 关键变化
- **STT P0→P3**：直播不需要语音识别
- **弹幕 P1→P0**：直播核心交互方式
- **表情 P1→P0**：芊芊模型资源丰富但闲置，接入成本低收益高
- **新增 4 个直播 feature**：弹幕智能选择、观众识别、礼物反应、主动话题
- **Adapter P1→P2**：当前单 provider 够用，先做核心体验
